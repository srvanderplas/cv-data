% Encoding: UTF-8

% ----- 2025 -----

@article{liAutomatedResidualPlot,
	title = {Automated Residual Plot Assessment With the R Package autovi and the Shiny Application autovi.web},
	issn = {1467-842X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/anzs.70027},
	doi = {10.1111/anzs.70027},
	abstract = {Visual assessment of residual plots is a common approach for diagnosing linear models, but it relies on manual evaluation, which does not scale well and can lead to inconsistent decisions across analysts. The lineup protocol, which embeds the observed plot among null plots, can reduce subjectivity but requires even more human effort. In today's data-driven world, such tasks are well suited for automation. We present a new R package that uses a computer vision model to automate the evaluation of residual plots. An accompanying Shiny application is provided for ease of use. Given a sample of residuals, the model predicts a visual signal strength ({VSS}) and offers supporting information to help analysts assess model fit.},
	journaltitle = {Australian \& New Zealand Journal of Statistics},
	author = {Li, Weihao and Cook, Dianne and Tanaka, Emi and Vanderplas, Susan and Ackermann, Klaus},
	urldate = {2025-10-13},
  date = {2025-10-09},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/anzs.70027},
	keywords = {computer vision, machine learning, model diagnostics, statistical graphics, perception, user testing, visual inference, pr},
}


@article{robinsonGuideDesigningExperiments2025,
  title = {A {{Guide}} to {{Designing Experiments}} to {{Test Statistical Graphics}}},
  author = {Robinson, Emily and Hofmann, Heike and Vanderplas, Susan},
  addendum     = {Writing (80\%)},
  author+an    = {1=student;3=highlight},
  year = {2025},
  journal = {WIREs Computational Statistics},
  volume = {17},
  number = {2},
  pages = {e70032},
  issn = {1939-0068},
  doi = {10.1002/wics.70032},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.70032},
  urldate = {2025-09-19},
  abstract = {In this paper, we discuss considerations and methods for experimentally testing visualizations. We discuss levels of user engagement with graphics, common issues when developing a sampling or data generation model, the importance of pilot testing, and data analysis methods. Along the way, we also provide recommendations of how to avoid some of the unique pitfalls of human testing in statistical and visualization research. This article is categorized under: Statistical and Graphical Methods of Data Analysis {$>$} Statistical Graphics and Visualization Statistical and Graphical Methods of Data Analysis {$>$} Modeling Methods and Algorithms},
  copyright = {All rights reserved},
  langid = {english},
  keywords = {data collection,experimental design,perception,statistical graphics, pr},
  file = {/home/susan/Nextcloud/Zotero/storage/VZMAPXWU/Robinson et al. - 2025 - A Guide to Designing Experiments to Test Statistical Graphics.pdf;/home/susan/Nextcloud/Zotero/storage/F8ZSIS9A/wics.html},
  pic = {https://i.imgur.com/qIoTTWh.jpeg}
}

@Article{robinsonPerceptionCognitiveImplications2025,
    author       = {Robinson, Emily A. and Howard, Reka and Vanderplas, Susan},
    title        = {Perception and Cognitive Implications of Logarithmic Scales for Exponentially Increasing Data: Perceptual Sensitivity Tested with Statistical Lineups},
    pages        = {1--14},
  addendum     = {Programming and analysis (10\%), Writing (10\%), Advising (70\%)},
  author+an    = {1=student;3=highlight},
  date         = {2025-03-11},
  doi          = {10.1080/10618600.2025.2476097},
  issue        = {ja},
  journal = {Journal of Computational and Graphical Statistics},
  keywords     = {pr, perception, user testing, log scales, visual inference},
  pic          = {https://i.imgur.com/JVvqE7P.png},
  shorttitle   = {Perception and Cognitive Implications of Logarithmic Scales for Exponentially Increasing Data},
}

@Article{Fudolig04042025,
  author    = {Fudolig, Miguel Antonio and Robinson, Emily A. and Vanderplas, Susan},
  title     = {Can You See The Change? Visual Perception in Change Point Analysis},
  journal   = {Journal of Computational and Graphical Statistics},
  date      = {2025-04-01},
  pages     = {1--15},
  abstract  = {Detecting change points is crucial in analyzing time series data and single-subject designs. This study investigates factors influencing change point detection through visual perception by employing a visual inference experiment. Participants were tasked with selecting the scatter plot that appeared most different from the surrounding plots. The” different” plot was generated to have a shift in the vertical direction compared to its counterparts with no vertical shift. We used a factorial experiment with a balanced incomplete block design to assign factor combinations for participants to evaluate. Furthermore, we compared the performance of visual accuracy to conventional change point detection methods. Participants were found to identify higher shift magnitudes more accurately than lower shift magnitudes, consistent with conventional methods. Change point data with higher variances had lower identification rates. Direction and change point location effects impacted identifying change point scenarios with lower signal-to-noise ratios. Participants indicated varying reasons for selection across correct and incorrect data plot identifications. Additionally, confidence in selection was positively associated with identification accuracy for change plots with higher signal-to-noise ratios. These insights highlight the complexities of change point detection through visual inference and emphasize the multifaceted nature of human perception in identifying subtle changes within data.},
  author+an = {2=student;3=highlight},
  doi       = {10.1080/10618600.2025.2485278},
  issue     = {ja},
  keywords  = {pr, perception, user testing, visual inference},
  pic       = {https://i.imgur.com/IC431w2.png},
}

% ----- 2024 -----

@article{cuellarMethodologicalProblemsEvery2024,
	title = {Methodological problems in every black-box study of forensic firearm comparisons},
	volume = {23},
	issn = {1470-8396},
	doi = {https://doi.org/10.1093/lpr/mgae015},
	number = {1},
  pages = {mgae015},
	keywords = {pr, forensics, error rates},
  addendum = {Writing (20\%).},
	journal = {Law, Probability and Risk},
	shortjournal = {Law, Probability and Risk},
	publisher = {Oxford University Press},
	author = {Cuellar, Maria and Vanderplas, Susan and Luby, Amanda and Rosenblum, Michael},
  author+an = {2=highlight},
	date = {2024-12-05},
	pic = {https://upload.wikimedia.org/wikipedia/commons/e/ec/NCI_swiss_cheese.jpg}
}

@Article{rosenblumIncorrectStatisticalReasoning2024,
  author    = {Rosenblum, Michael and Chin, Elizabeth T. and Ogburn, Elizabeth L. and Nishimura, Akihiko and Westreich, Daniel and Datta, Abhirup and Vanderplas, Susan and Cuellar, Maria and Thompson, William C.},
  title     = {Incorrect statistical reasoning in {Guyll et al.} leads to biased claims about strength of forensic evidence},
  journal   = {Proceedings of the National Academy of Sciences},
  volume    = {121},
  number    = {45},
  pages     = {e2315431121},
  author+an = {7=highlight},
  date      = {2024-11-05},
  doi       = {https://doi.org/10.1073/pnas.2315431121},
  keywords  = {letter, forensics, error rates},
  pic       = {https://www.pnas.org/cms/10.1073/pnas.2315431121/asset/ed2391a4-340e-45d5-9699-fdd960bacd37/assets/images/large/pnas.2315431121fig01.jpg},
  publisher = {National Academy of Sciences},
}


@article{vanderplasHiddenMultipleComparisons2024,
  title = {Hidden Multiple Comparisons Increase Forensic Error Rates},
  author = {Vanderplas, Susan and Carriquiry, Alicia and Hofmann, Heike},
  year = {2024},
  month = {6},
  date = {2024-06-10},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {121},
  number = {25},
  pages = {e2401326121},
  publisher = {National Academy of Sciences},
  doi = {https://doi.org/10.1073/pnas.2401326121},
  abstract = {When wires are cut, the tool produces striations on the cut surface; as in other forms of forensic analysis, these striation marks are used to connect the evidence to the source that created them. Here, we argue that the practice of comparing two wire cut surfaces introduces complexities not present in better-investigated forensic examination of toolmarks such as those observed on bullets, as wire comparisons inherently require multiple distinct comparisons, increasing the expected false discovery rate. We call attention to the multiple comparison problem in wire examination and relate it to other situations in forensics that involve multiple comparisons, such as database searches.},
  author+an = {1=highlight},
  addendum = {Programming and analysis (50\%), Writing 70\%},
  keywords = {pr, forensics, error rates},
  github = {https://github.com/srvanderplas/Wire-Cut-Errors},
  pic = {https://i.imgur.com/JXILntV.png}
}

@article{wiederichEvaluatingPerceptualJudgements2024,
	title = {Evaluating Perceptual Judgements on 3D Printed Bar Charts},
	volume = {22},
	issn = {1680743X},
	doi = {https://doi.org/10.6339/24-JDS1131},
	abstract = {Graphical design principles typically recommend minimizing the dimensionality of a visualization - for instance, using only 2 dimensions for bar charts rather than providing a 3D rendering, because this extra complexity may result in a decrease in accuracy. This advice has been oft repeated, but the underlying experimental evidence is focused on fixed 2D projections of 3D charts. In this paper, we describe an experiment which attempts to establish whether the decrease in accuracy extends to 3D virtual renderings and 3D printed charts. We replicate the grouped bar chart comparisons in the 1984 Cleveland \& {McGill} study, assessing the accuracy of numerical estimates using different types of 3D and 2D renderings.},
	pages = {176--190},
	number = {2},
	journal = {Journal of Data Science},
	author = {Wiederich, Tyler and Vanderplas, Susan},
  publisher = {School of Statistics, Renmin University of China},
	date = {2024-04-24},
	author+AN = {1=student;2=highlight},
	keywords = {pr, 3d, visualization, user testing, experiential learning},
  github = {https://github.com/TWiedRW/2023-JDS-3dcharts},
  addendum = {Programming and analysis (40\%), Writing (60\%), Advising (100\%)},
}


@article{liPlotWorthThousand2024,
  title = {A {{Plot}} Is {{Worth}} a {{Thousand Tests}}: {{Assessing Residual Diagnostics}} with the {{Lineup Protocol}}},
  shorttitle = {A {{Plot}} Is {{Worth}} a {{Thousand Tests}}},
  author = {Li, Weihao and Cook, Dianne and Tanaka, Emi and VanderPlas, Susan},
  year = {2024},
  month = {5},
  date = {2024-05-22},
  pages = {1497--1511},
  journal = {Journal of Computational and Graphical Statistics},
  publisher = {Taylor & Francis},
  issn = {1061-8600},
  doi = {https://doi.org/10.1080/10618600.2024.2344612},
  abstract = {Regression experts consistently recommend plotting residuals for model diagnosis, despite the availability of many numerical hypothesis test procedures designed to use residuals to assess problems ...},
  langid = {english},
  author+an = {4=highlight; 1=student},
  addendum = {Advising 10\%},
  keywords = {pr, graphics, visual inference, computer vision},
  github = {https://github.com/TengMCing/lineup_residual_diagnostics}
}

@article{juOneModelThat2024,
  title = {One {{Model}} That {{Fits Them All}}: {{Psychometrics With Generalized Linear Mixed Effects Models}}},
  shorttitle = {One {{Model}} That {{Fits Them All}}},
  author = {Ju, Wangqian and VanderPlas, Susan and Hofmann, Heike},
  year = {2024},
  month = {1},
  date = {2024-01-24},
  journal = {Electronic Imaging},
  volume = {36},
  pages = {1--8},
  publisher = {Society for Imaging Science and Technology},
  doi = {https://doi.org/10.2352/EI.2024.36.1.VDA-358},
  abstract = {User experiments are essential for informing researchers what an audience is seeing in a chart. User experiments are generally quite expensive in monetary value and in the time spent getting data. It is crucial that we make the most out of the data we get from participants. Statistically, the best practice for data with repeated measurements is the use of (Generalized) Linear Mixed Effects Models (GLME). These models increase the statistical power, produce more reliable estimates, and provide better interpretability for population-level and individual-level effects. However, in the literature, a two-stage approach for analyzing results from user experiments is commonly used. We compare the two approaches with example data from psychophysics experiments. We present a strategy on how to evolve a two-stage analysis to a single GLME model and showcase diagnostics for each step of that process. We adhere to the best practices of open science and reproducible research by providing open access to all of our code and data.},
  langid = {english},
  author+an = {2=highlight},
  addendum = {Advising 10\%},
  keywords = {pr, graphics, psychometrics, modeling}
}

@Article{rogersDemonstrativeEvidenceUse2024,
  author    = {Rogers, Rachel and VanderPlas, Susan},
  title     = {Demonstrative {{Evidence}} and the {{Use}} of {{Algorithms}} in {{Jury Trials}}},
  journal   = {Journal of Data Science},
  year      = {2024},
  volume    = {22},
  number    = {2},
  pages     = {314--332},
  month     = may,
  abstract  = {We investigate how the use of bullet comparison algorithms and demonstrative evidence may affect juror perceptions of reliability, credibility, and understanding of expert witnesses and presented evidence. The use of statistical methods in forensic science is motivated by a lack of scientific validity and error rate issues present in many forensic analysis methods. We explore what our study says about how this type of forensic evidence is perceived in the courtroom -- where individuals unfamiliar with advanced statistical methods are asked to evaluate results in order to assess guilt. In the course of our initial study, we found that individuals overwhelmingly provided high Likert scale ratings in reliability, credibility, and scientificity regardless of experimental condition. This discovery of scale compression - where responses are limited to a few values on a larger scale, despite experimental manipulations - limits statistical modeling but provides opportunities for new experimental manipulations which may improve future studies in this area.},
  addendum  = {Writing 20\%, Advising 100\%},
  author+an = {2=highlight; 1=student},
  date      = {2024-05-02},
  doi       = {https://doi.org/10.6339/24-JDS1130},
  github    = {https://github.com/rachelesrogers/Algorithms_in_Jury_Trials},
  keywords  = {pr, forensics, firearms, jury trials, algorithms},
  langid    = {english},
  pic       = {https://i.imgur.com/ae6Sa8U.png},
  publisher = {School of Statistics, Renmin University of China},
}

@inproceedings{vanderplasEscapingFlatlandGraphics2024,
  title = {Escaping {Flatland}: {Graphics}, {Dimensionality}, and~{Human Perception}},
  shorttitle = {Escaping {Flatland}},
  booktitle = {Human {Interface} and the {Management} of {Information}},
  author = {Vanderplas, Susan and Blankenship, Erin and Wiederich, Tyler},
  editor = {Mori, Hirohiko and Asahi, Yumi},
  year = {2024},
  date = {2024-07-01},
  pages = {140--156},
  publisher = {Springer Nature Switzerland},
  doi = {https://doi.org/10.1007/978-3-031-60114-9_11},
  abstract = {Almost 40~years ago, Cleveland and McGill published the first of 3 papers detailing experiments assessing the accuracy of numerical perception using different types of charts. This study is often cited as a reason to avoid the use of extraneous dimensions in data visualization: 2D bar charts produced more accurate estimates than 3D bar charts; in addition, lines (length) produced more accurate estimates than circles (area). Graphics have changed fairly significantly in the last 40~years: where we once had fixed 3D perspective charts, we now can rotate 3D renderings in digital space and even 3D print our charts to examine physically. Many optical illusions result from perceptual mismatches of 3D visual heuristics and 2D, planar, data representations; more realistic renderings available with modern tools might change the outcome of Cleveland and McGill's experimental comparison of 2D vs.~3D accuracy. In this paper, we present several experiments which replicate the bar chart portion of Cleveland and McGill's original study, comparing 2D, 3D fixed perspective, 3D rendered, and 3D printed charts. We discuss the findings and the importance of replicating classic experiments using modern technology, as well as the benefits of incorporating hands-on research in introductory classes as experiential learning activities.},
  isbn = {978-3-031-60114-9},
  langid = {english},
  author+an = {1=highlight; 3=student},
  addendum = {Writing 100\%, Analysis 70\%},
  keywords = {pr, graphics, 3D, perception, teaching, user-study},
  github = {https://github.com/srvanderplas/2024-hcii-escaping-flatland},
  pic = {https://github.com/srvanderplas/2024-hcii-escaping-flatland/blob/main/image/Kit_of_charts.png?raw=true}
}

@article{rosenblumMisuseStatisticalMethod2024,
	title = {Misuse of statistical method results in highly biased interpretation of forensic evidence in Guyll et al. (2023)},
	volume = {23},
	doi = {https://doi.org/10.1093/lpr/mgad010},
	number = {1},
	journal = {Law, Probability and Risk},
	publisher = {Oxford University Press},
  pages = {mgad010},
	author = {Rosenblum, Michael and Chin, Elizabeth T and Ogburn, Elizabeth L and Nishimura, Akihiko and Westreich, Daniel and Datta, Abhirup and Vanderplas, Susan and Cuellar, Maria and Thompson, William C},  
  author+an = {7=highlight},
  addendum = {Writing (10\%). This paper is a collaboration between all authors resulting from discussions about the Guyll et al. paper.},
  keywords = {pr, forensics, error rates},
	date = {2024-01-09},
  pic = {https://www.pnas.org/cms/10.1073/pnas.2315431121/asset/ed2391a4-340e-45d5-9699-fdd960bacd37/assets/images/large/pnas.2315431121fig01.jpg}
}

% ----- 2023 -----

@article{robinsonEyeFittingStraight2023,
	title = {Eye Fitting Straight Lines in the Modern Era},
	volume = {32},
	issn = {1061-8600},
	doi = {https://doi.org/10.1080/10618600.2022.2140668},
	abstract = {How do statistical regression results compare to intuitive, visually fitted results? Fitting lines by eye through a set of points has been explored since the 20th century. Common methods of fitting trends by eye involve maneuvering a string, black thread, or ruler until the fit is suitable, then drawing the line through the set of points. In 2015, the New York Times introduced an interactive feature, called “You Draw It,” where readers were asked to input their own assumptions about various metrics and compare how these assumptions relate to reality. In this article, we validate “You Draw It” as a method for graphical testing, comparing results to the less technological method used in Mosteller et al. and extending that study with formal statistical analysis methods. Results were consistent with those found in the previous study; when shown points following a linear trend, participants tended to fit the slope of the principal axis over the slope of the least-squares regression line. This trend was most prominent when shown data simulated with larger variances. This study reinforces the differences between intuitive visual model fitting and statistical model fitting, providing information about human perception as it relates to the use of statistical graphics. Supplementary materials for this article are available online.},
	pages = {1537--1544},
	number = {4},
	journal = {Journal of Computational and Graphical Statistics},
	publisher = {Taylor & Francis},
	author = {Robinson, Emily A. and Howard, Reka and {VanderPlas}, Susan},
	date = {2023-10-02},
  keywords = {pr, perception, user testing, visualization},
  author+an = {3=highlight; 1=student},
  github = {https://github.com/earobinson95/Eye-Fitting-Straight-Lines-in-the-Modern-Era},
  addendum = {Programming and analysis (10\%), Writing (10\%), Advising (60\%)},
  pic = {https://github.com/earobinson95/Eye-Fitting-Straight-Lines-in-the-Modern-Era/blob/main/images/ydi-stimuli.png?raw=true}
}

@article{ggpcp,
  author = {Susan VanderPlas and Yawei Ge and Antony Unwin and Heike Hofmann},
  title = {Penguins Go Parallel: a grammar of graphics framework for generalized parallel coordinate plots},
  journal = {Journal of Computational and Graphical Statistics},
	publisher = {Taylor & Francis},
  volume = {32},
  number = {4},
  pages = {1572--1587},
  year = {2023}, 
  date = {2023-04-21},
  doi = {https://doi.org/10.1080/10618600.2023.2195462},
  abstract = { Parallel Coordinate Plots (PCP) are a valuable tool for exploratory data analysis of high-dimensional numerical data. The use of PCPs is limited when working with categorical variables or a mix of categorical and continuous variables. In this article, we propose Generalized Parallel Coordinate Plots (GPCP) to extend the ability of PCPs from just numeric variables to dealing seamlessly with a mix of categorical and numeric variables in a single plot. In this process we find that existing solutions for categorical values only, such as hammock plots or parsets become edge cases in the new framework. By focusing on individual observations rather than a marginal frequency we gain additional flexibility. The resulting approach is implemented in the R package ggpcp. Supplementary materials for this article are available online. },
  keywords = {pr, perception, visualization, R package, parallel coordinate plot, multivariate},
  author+an = {1=highlight; 2=student},
  github = {https://github.com/srvanderplas/ggpcp-paper},
  addendum = {Writing (50\%)},
  pic = {https://github.com/srvanderplas/ggpcp-paper/blob/main/figures/carcinoma-1.png?raw=true}
}

@article{cmcR,
  title = {A Study in Reproducibility: The Congruent Matching Cells Algorithm and cmcR package},
  author = {Zemmels, Joseph and Vanderplas, Susan and Hofmann, Heike},
  journal = {R Journal},
  publisher = {R Foundation},
  number = 14,
  issue = 4,
  doi = {https://doi.org/10.32614/RJ-2023-014},
	date = {2023-02-09},
	pages = {79--102},
  addendum = {Programming and analysis (10\%), Writing (20\%), Advising (40\%)},
  keywords = {pr, R package, forensics, firearms, algorithms, reproducibility, machine learning},
  author+an = {2=highlight; 1=student},
  github = {https://github.com/jzemmels/cmcRwriteup},
  pic = {https://github.com/jzemmels/cmcRwriteUp/blob/master/images/cmc_illustration.PNG?raw=true}
}
 
@article{robinsonvanderplas2023,
  author = {Emily Robinson and Reka Howard and Susan VanderPlas},
  title = {You Draw It: Implementation of visually fitted trends with r2d3},
  journal = {Journal of Data Science},
  volume = {21},
  issue = {2},
  year = {2023},
  pages = {281--294},
  issn = {1680-743X},
  doi = {https://doi.org/10.6339/22-JDS1083},
  publisher = {School of Statistics, Renmin University of China},
  keywords = {pr, perception, visualization, covid, log scales, user testing},
  date = {2023-01-12},
  author+an = {3=highlight; 1=student},
  github = {https://github.com/earobinson95/sdss-2022-you-draw-it-manuscript},
  addendum = {Writing (10\%), Advising (80\%)},
  pic = {https://github.com/earobinson95/sdss-2022-you-draw-it-manuscript/blob/master/images/ydi-stimuli.png?raw=true}
}


% ----- 2022 -----

@article{bradfordvanderplas2022,
  author = { Bradford,Denise and VanderPlas,Susan },
  title = {Exploring Rural Shrink Smart Through Guided Discovery Dashboards},
  journal = {Journal of Data Science},
  year = {2022},
  month = {12},
  pages = {1--12},
  doi = {https://doi.org/10.6339/22-JDS1080},
  issn = {1680-743X},
  publisher = {School of Statistics, Renmin University of China},
  keywords = {pr, perception, visualization, small communities},
  date = {2022-12},
  addendum = {Programming and analysis (10\%), Writing (10\%), Advising (100\%)},
  author+an = {2=highlight; 1=student},
  github = {https://github.com/drbradford12/SDSS-Abstract-2022},
  pic = {https://github.com/drbradford12/SDSS-2022/blob/main/SDSS%20Journal%20Paper/images/map.png?raw=true}
}

@article{covidnarratives, 
  author = {Wilhelm, Adalbert and VanderPlas, Susan}, 
  title = {Visual Narratives of the Covid-19 pandemic},   
  journal = {Journal of Data Science, Statistics, and Visualisation}, 
  publisher = {International Association for Statistical Computing},
  volume = {2}, 
  number = {7}, 
  date = {2022-11-01},
  pages = {84--113},
  doi = {https://doi.org/10.52933/jdssv.v2i7.64}, 
  author+an = {2=highlight},
  addendum = {Writing (60\%)},
  keywords = {pr, perception, visualization, journalism, covid},
  github = {https://github.com/srvanderplas/covid-visualization-dssv},
  pic = {https://github.com/srvanderplas/covid-visualization-dssv/blob/master/Figures_Web/spiral-rework.jpeg?raw=true}
}

% ----- 2021 -----

@article{vanderplasDesigningGraphicsRequires2021,
	author = {VanderPlas, Susan},
	title = {Designing {Graphics} {Requires} {Useful} {Experimental} {Testing} {Frameworks} and {Graphics} {Derived} {From} {Empirical} {Results}},
	journal = {Harvard Data Science Review},
	publisher = {MIT Press},
	volume = {3},
	number = {3},
	date = {2021-07-30},
	year = {2021},
	month = {7},
	abstract = {Hullman and Gelman (2021, this issue) have provided a very thorough discussion of the premise that interactive exploratory data analysis requires a theoretical framework for graphical inference to effectively support the analyst and counter any tendencies towards assuming all results are real and not just due to sample variability. Unfortunately, the theoretical framework for model checking during exploratory and confirmatory data analysis proposed in this paper is just another conceptual and theoretical framework that is difficult to test or falsify as presented.},
  doi = {https://doi.org/10.1162/99608f92.7d099fd0},
  keywords = {npr, user testing, visualization, modeling},
  author+an = {1=highlight},
  pic = {https://i.imgur.com/MMBggrj.png}
}

@article{inconclusives,
  author = {Hofmann, Heike and Carriquiry, Alicia and Vanderplas, Susan},
  title = {Treatment of inconclusives in the {AFTE} range of conclusions},
  journal = {Law, Probability and Risk},
	publisher = {Oxford University Press},
  volume = {19},
  number = {3-4},
  pages = {317--364},
  year = {2021},
  month = {5},
  abstract = {In the past decade, and in response to the recommendations set forth by the National Research Council Committee on Identifying the Needs of the Forensic Sciences Community (2009), scientists have conducted several black-box studies that attempt to estimate the error rates of firearm examiners. Most of these studies have resulted in vanishingly small error rates, and at least one of them (D. P. Baldwin, S. J. Bajic, M. Morris, and D. Zamzow. A Study of False-Positive and False-Negative Error Rates in Cartridge Case Comparisons. Technical report, Ames Lab IA, Performing, Fort Belvoir, VA, April 2014.) was cited by the President’s Council of Advisors in Science and Technology (PCAST) during the Obama administration, as an example of a well-designed experiment. What has received little attention, however, is the actual calculation of error rates and in particular, the effect of inconclusive findings on those error estimates. The treatment of inconclusives in the assessment of errors has far-reaching implications in the legal system. Here, we revisit several black-box studies in the area of firearms examination, investigating their treatment of inconclusive results. It is clear that there are stark differences in the rate of inconclusive results in regions with different norms for training and reporting conclusions. More surprisingly, the rate of inconclusive decisions for materials from different sources is notably higher than the rate of inconclusive decisions for same-source materials in some regions. To mitigate the effects of this difference we propose a unifying approach to the calculation of error rates that is directly applicable in forensic laboratories and in legal settings.},
  issn = {1470-8396},
  doi = {https://doi.org/10.1093/lpr/mgab002},
	date = {2021-05-05},
  author+an = {3=highlight},
	github = {https://github.com/heike/inconclusives},
  keywords = {pr, forensics, firearms, error rates, inconclusives},
  addendum = {Writing (50\%)},
  pic = {https://github.com/heike/inconclusives/blob/master/figures/shape-overview-study-1.png?raw=true}
}

% ----- 2020 -----

@article{stat2020,
  author = {Vanderplas, Susan and Röttger, Christian and Cook, Dianne and Hofmann, Heike},
  title = {Statistical significance calculations for scenarios in visual inference},
  journal = {Stat},
  publisher = {Wiley},
  volume = {10},
  number = {1},
  pages = {e337},
  doi = {https://doi.org/10.1002/sta4.337},
  year = {2021},
  date = {2021-12-01},
  abstract = {Statistical inference provides the protocols for conducting rigorous science, but data plots provide the opportunity to discover the unexpected. These disparate endeavours are bridged by visual inference, where a lineup protocol can be employed for statistical testing. Human observers are needed to assess the lineups, typically using a crowd-sourcing service. This paper describes a new approach for computing statistical significance associated with the results from applying a lineup protocol. It utilizes a Dirichlet distribution to accommodate different levels of visual interest in individual null panels. The suggested procedures facilitate statistical inference for a broader range of data problems.},
  author+an = {1=highlight},
  github = {https://github.com/srvanderplas/visual-inference-alpha},
  keywords = {pr, visual inference, user testing, perception, visualization},
  addendum = {Programming and analysis (30\%), Writing (65\%)},
  pic = {https://i.imgur.com/D9ZpjyJ.png}
}

@incollection{vanderplasIntroductionFirearmsExamination2020,
	title = {An introduction to firearms examination for researchers in statistics},
	doi = {https://doi.org/10.1201/9780367527709},
	booktitle = {Handbook of {Forensic} {Statistics}},
	pages = {365--390},
	publisher = {New York: Chapman and Hall/CRC},
	author = {Vanderplas, Susan and Carriquiry, Alicia and Hofmann, Heike and Hamby, James and Tai, Xiao Hui},
	editor = {{Banks, D.} and {Kafadar, K.} and {Kaye, D.} and {Tackett, M.}},
	year = {2020},
	date = {2022-05-30},
	abstract = {In the United States, where firearms are readily accessible, the annual number of gun-related crimes is in the hundreds of thousands, and about two thirds of all murders are committed with a gun. Visual comparisons are problematic for several reasons, including the fact that the assessment of similarity is typically subjective, and consequently, estimation of error rates is difficult. Machine learning can be used to augment the subjective perceptions of examiners, providing a quantitative foundation for the assessment of questions of source in firearms examination. In order to leverage machine learning techniques for firearm identification, researchers mostly use supervised learning algorithms and large amounts of labeled training data, called a training set, to assess how features from the data relate to the labels. Firearms examination became more of a discipline in the 1930s, with textbooks published on the subject in both the UK and the United States.},
  addendum = {Writing (50\%)},
  keywords = {bookch, forensics, firearms, algorithms, machine learning},
  github = {https://github.com/srvanderplas/2019_book_chapter},
  author+an = {1=highlight},
  pic = {https://github.com/srvanderplas/2019_book_chapter/blob/master/figure/Luger-Cutaway.png?raw=true}
}

@article{vanderplasComparisonThreeSimilarity2020,
  title = {Comparison of three similarity scores for bullet LEA matching},
  author = {Vanderplas, Susan and Nally, Melissa and Klep, Tylor and Cadevall, Cristina and Hofmann, Heike},
  journal = {Forensic Science International},
  publisher = {Elsevier},
  volume = {308},
  pages = {110167},
  year = {2020},
  date = {2020-03-01},
  issn = {0379-0738},
  doi = {https://doi.org/10.1016/j.forsciint.2020.110167},
  abstract = {Recent advances in microscopy have made it possible to collect 3D topographic data, enabling more precise virtual comparisons based on the collected 3D data as a supplement to traditional comparison microscopy and 2D photography. Automatic comparison algorithms have been introduced for various scenarios, such as matching cartridge cases [1], [2] or matching bullet striae [3], [4], [5]. One key aspect of validating these automatic comparison algorithms is to evaluate the performance of the algorithm on external tests, that is, using data which were not used to train the algorithm. Here, we present a discussion of the performance of the matching algorithm [6] in three studies conducted using different Ruger weapons. We consider the performance of three scoring measures: random forest score, cross correlation, and consecutive matching striae (CMS) at the land-to-land level and, using Sequential Average Maxima scores, also at the bullet-to bullet level. Cross correlation and random forest scores both result in perfect discrimination of same-source and different-source bullets. At the land-to-land level, discrimination for both cross correlation and random forest scores (based on area under the curve, AUC) is excellent.},
  keywords = {pr, forensics, firearms, algorithms, machine learning},
  addendum = {Programming and analysis (20\%), Writing (55\%)},
  github = {https://github.com/heike/case-study-validation},
  author+an = {1=highlight},
  pic = {https://github.com/heike/case-study-validation/blob/master/images/B8-B2-L2.png?raw=true}
}

@article{vanderplasTestingStatisticalCharts2020,
  author = {Vanderplas, Susan and Cook, Dianne and Hofmann, Heike},
  title = {Testing Statistical Charts: What Makes a Good Graph?},
  journal = {Annual Review of Statistics and Its Application},
  publisher = {Annual Reviews},
  volume = {7},
  number = {1},
  pages = {61-88},
  year = {2020},
  date = {2020-03-01},
  doi = {https://doi.org/10.1146/annurev-statistics-031219-041252},
  abstract = { It has been approximately 100 years since the very first formal experimental evaluations of statistical charts were conducted. In that time, technological changes have impacted both our charts and our testing methods, resulting in a dizzying array of charts, many different taxonomies to classify graphics, and several different philosophical approaches to testing the efficacy of charts and graphs experimentally. Once rare, charts and graphical displays are now everywhere—but do they help us understand? In this article we review the history of graphical testing across disciplines, discuss different direct approaches to testing graphics, and contrast direct tests with visual inference, which requires that the viewer determine both the question and the answer. Examining the past 100 years of graphical testing, we summarize best practices for creating effective graphics and discuss what the future holds for graphics and empirical testing of interactive statistical visualizations. },
  keywords = {pr, visualization, user testing, visual inference, perception, design, review},
  github = {https://github.com/srvanderplas/AnnualReviewStatisticsVisualization},
  author+an = {1=highlight},
  addendum = {Writing (85\%)},
  pic = {https://github.com/srvanderplas/AnnualReviewStatisticsVisualization/blob/master/figure/noaa_michael.png?raw=true}
}

% ----- 2019 -----

@Article{rutter2019ggenealogy,
	title = {ggenealogy: {An} {R} {Package} for {Visualizing} {Genealogical} {Data}},
	volume = {89},
	doi = {https://doi.org/10.18637/jss.v089.i13},
	number = {13},
	journal = {Journal of Statistical Software},
	publisher = {Foundation for Open Access Statistics},
	author = {Rutter, Lindsay and Vanderplas, Susan and Cook, Dianne and Graham, Michelle},
	year = {2019},
	date = {2019-05-29},
	pages = {1-31},
	abstract = {This paper introduces ggenealogy (Rutter, Vanderplas, and Cook 2019), a developing R software package that provides tools for searching through genealogical data, generating basic statistics on their graphical structures using parent and child connections, parsing and performing calculations on branches of interest, and displaying the results. It is possible to draw the genealogy in relation to variables related to the nodes, and to determine and display the shortest path distances between the nodes. Production of pairwise distance matrices and genealogical diagrams constrained on generation are also available in the visualization toolkit. The tools are being tested on a dataset with milestone cultivars of soybean varieties (Hymowitz, Newell, and Carmer 1977) as well as on a web-based database of the academic genealogy of mathematicians (North Dakota State University and American Mathematical Society 2010). The latest stable package version is available in source and binary form on the Comprehensive R Archive Network (CRAN).},
  author+an = {2=highlight},
  keywords = {pr, genealogy, visualization, R package, exploratory data analysis, interactive},
  pic = {https://github.com/lindsayrutter/ggenealogy/blob/master/vignettes/dCox.png?raw=true}
}

@article{framedjcgs,
  author = {Vanderplas, Susan and Goluch, Ryan C and Hofmann, Heike},
  title = {Framed! Reproducing and Revisiting 150-Year-Old Charts},
  journal = {Journal of Computational and Graphical Statistics},
  volume = {28},
  number = {3},
  pages = {620-634},
  year  = {2019},
  date = {2019-04-01},
  publisher = {Taylor & Francis},
  doi = {https://doi.org/10.1080/10618600.2018.1562937},
  abstract = { AbstractThe Statistical Atlases published by the Census Bureau in the late 1800s utilized a number of novel methods for displaying data. In this paper, we examine the use of framed spine and mosaic plots used in two plates of the Statistical Atlas of 1870. We use forensic statistics to recreate the data using available census information, and then use that data to create framed charts using modern plotting methods. We then examine the effectiveness of the framed charts compared to other alternatives with a user study. The data and code for this study are available online. },
  author+an = {1=highlight},
  addendum = {Programming and analysis (60\%), writing (50\%)},
  github = {https://github.com/srvanderplas/Statistical_Atlas},
  keywords = {pr, statistical atlas, visualization, design, user testing},
  pic = {https://github.com/srvanderplas/Statistical_Atlas/blob/master/images/test-images/Oregon-spine_with_frame1.png?raw=true}
}

@article{sievert2018extending,
  author = {Sievert, Carson  and Vanderplas, Susan and Cai, Jun  and Ferris, Kevin and Khan, Faizan Uddin Fahad and Hocking, Toby Dylan},
  title = {Extending ggplot2 for Linked and Animated Web Graphics},
  journal = {Journal of Computational and Graphical Statistics},
  volume = {28},
  number = {2},
  pages = {299-308},
  year = {2019},  
  date = {2019-04-01},
  publisher = {Taylor & Francis},
  doi = {https://doi.org/10.1080/10618600.2018.1513367},
  abstract = {Interactive web graphics are great for communication and knowledge sharing, but are difficult to leverage during the exploratory phase of a data science workflow. Even before the web, interactive graphics helped data analysts quickly gather insight from data, discover the unexpected, and develop better model diagnostics. Although web technologies make interactive graphics more accessible, they are not designed to fit inside an exploratory data analysis (EDA) workflow where rapid iteration between data manipulation, modeling, and visualization must occur. To better facilitate exploratory web graphics that are easily distributed, we need better interfaces between statistical computing environments (e.g., the R language) and client-side web technologies. We propose the R package animint for rapid creation of linked and animated web graphics through a simple extension of ggplot2’s implementation of the Grammar of Graphics. The extension allows one to write ggplot2 code and produce a standalone web page with multiple linked views. Supplementary material for this article is available online. },
  keywords = {pr, animation, exploratory data analysis, visualization, R package, animation},
  author+an = {2=highlight},
  pic = {https://github.com/tdhock/animint/raw/master/screencast-WorldBank.gif},
}

@article{machinelearningforensics2019,
  author = {Carriquiry, Alicia and Hofmann, Heike and Tai, Xiao Hui and Vanderplas, Susan},
  title = {Machine learning in forensic applications},
  journal = {Significance},
  publisher = {Oxford University Press},
  volume = {16},
  number = {2},
  pages = {29-35},
  abstract = {The 2009 National Academy of Sciences report found pattern-evidence disciplines to be rife with subjectivity. In the decade since, machine learning methods have been developed to try to address that issue. },
  doi = {https://doi.org/10.1111/j.1740-9713.2019.01252.x},
  year = {2019},
  date = {2019-04-01},
  keywords = {npr, forensics, machine learning, algorithms},
  addendum = {Writing (50\%)},
  author+an = {4=highlight},
  pic = {https://rss.onlinelibrary.wiley.com/cms/asset/4792a2d6-f10b-481e-aeff-075d0ccdd90e/sign1252-fig-0001-m.png}
}
  

% ----- 2017 -----

@Article{featurehierarchyjcgs,
  Title = {{C}lusters Beat {T}rend!? {T}esting Feature Hierarchy in Statistical Graphics},
  Author = {Vanderplas, Susan and Hofmann, Heike},
  Journal = {Journal of Computational and Graphical Statistics},
  publisher = {Taylor & Francis},
  Year = {2017},
  date = {2017-04-24},
  Number = {2},
  Pages = {231-242},
  Volume = {26},
  doi = {https://doi.org/10.1080/10618600.2016.1209116},
  abstract = {Graphics are very effective for communicating numerical information quickly and efficiently, but many of the design choices we make are based on subjective measures, such as personal taste or conventions of the discipline rather than objective criteria. We briefly introduce perceptual principles such as preattentive features and gestalt heuristics, and then discuss the design and results of a factorial experiment examining the effect of plot aesthetics such as color and trend lines on participants’ assessment of ambiguous data displays. The quantitative and qualitative experimental results strongly suggest that plot aesthetics have a significant impact on the perception of important features in data displays. Supplementary materials for this article are available online.},
  author+an = {1=highlight},
  addendum = {Programming and analysis (90\%), writing (50\%)},
  github = {https://github.com/srvanderplas/FeatureHierarchy},
  keywords = {pr, design, user testing, visual inference, visualization},
  pic = {https://github.com/srvanderplas/FeatureHierarchy/raw/master/pngs/1b4491b66980539a3d929485874ac41a.png}
}
@article{donohoresponse,
  title = {All of This Has Happened Before. {A}ll of This Will Happen Again: {D}ata {S}cience},
  author = {Hofmann, Heike and Vanderplas, Susan},  
  journal = {Journal of Computational and Graphical Statistics},
  doi = {https://doi.org/10.1080/10618600.2017.1385474},
  volume = {26},
  number = {4},
  pages = {775-778},
  year = {2017},
  date = {2017-12-19},
  publisher = {Taylor & Francis},
  abstract = {David Donoho’s “50 Years of Data Science” provides a valuable perspective on the statistics-vs-data science debate that has been raging in academic statistics departments over the past couple of years. The debate about the relative merits of theoretical and applied statistics flares up occasionally, and even in the infancy of statistics as a discipline distinct from mathematics, there was “something slightly disreputable about mathematical statistics” because of its applied nature (Salsburg 2001, p. 208). It seems, however, that we may be witnessing the birth of the academic discipline of data science as a separate entity from statistics. While data science itself has been, according to Donoho, around for 50 years or more, academic initiatives focusing on the practice of data analysis are becoming ever more popular.},
  keywords = {npr, data science, statistics, computing},
  author+an = {2=highlight},
  addendum = {Writing (75\%)},
  pic = {https://i.imgur.com/WHkmWIH.png}
}
@Article{visualaptitude,
  author = {VanderPlas, Susan and Hofmann, Heike},
  journal = {IEEE Transactions on Visualization and Computer Graphics}, 
  publisher = {IEEE},
  title = {Spatial Reasoning and Data Displays}, 
  doi = {https://doi.org/10.1109/TVCG.2015.2469125},
  year = {2016},
  date = {2016-12-31},
  volume = {22},
  number = {1},
  pages = {459-468},
  abstract = {Graphics convey numerical information very efficiently, but rely on a different set of mental processes than tabular displays. Here, we present a study relating demographic characteristics and visual skills to perception of graphical lineups. We conclude that lineups are essentially a classification test in a visual domain, and that performance on the lineup protocol is associated with general aptitude, rather than specific tasks such as card rotation and spatial manipulation. We also examine the possibility that specific graphical tasks may be associated with certain visual skills and conclude that more research is necessary to understand which visual skills are required in order to understand certain plot types.},
  github = {https://github.com/srvanderplas/VisualAptitude},
  keywords = {pr, user testing, perception, visualization},
  author+an = {1=highlight},
  addendum = {Programming and analysis (90\%), writing (75\%)},
  pic = {https://github.com/srvanderplas/VisualAptitude/blob/master/Presentation/figure/scaledscores-1.png?raw=true}
}
@Article{sineillusionjcgs,
  Title = {Signs of the Sine Illusion - why we need to care},
  author = {Vanderplas, Susan and Hofmann, Heike},
  journal = {Journal of Computational and Graphical Statistics},
  publisher = {Taylor & Francis},
  volume = {24},
  number = {4},
  pages = {1170-1190},
  year = {2015},
  date = {2015-12-10},
  abstract = {Graphical representations have to be true to the data they display. Computational tools ensure this on a technical level. But we also need to take “flaws” of the human perceptual system into account. The sine illusion provides an example where human perception leads to systematic bias in the assessment of the optical stimulus, with a particularly notable impact on perception of time-series data with a seasonal component. In this article, we discuss the reasons for the illusion and various strategies useful to break the illusion or reduce its strength. We demonstrate the presence of the illusion in real-world and theoretical situations. We also present data from a user study, which demonstrate the dramatic effect the sine illusion can have on conclusions drawn from displayed data.},
  doi = {https://doi.org/10.1080/10618600.2014.951547},
  author+an = {1=highlight},
  addendum = {Programming and analysis (50\%), writing (60\%)},
  github = {https://github.com/heike/sine-illusion},
  keywords = {pr, visualization, perception, illusion, user testing},
  pic = {https://github.com/heike/sine-illusion/raw/master/figure/fig-origillusion.png}
}
@article{budrus2013tennis,
  author = {Budrus, Sarah and Vanderplas, Susan and Cook, Dianne},
  title = {In tennis, do smashes win matches?},
  journal = {Significance},
  publisher = {Oxford University Press},
  date = {2013-06-13},
  volume = {10},
  number = {3},
  pages = {35-38},
  doi = {https://doi.org/10.1111/j.1740-9713.2013.00665.x},
  abstract = {It is summer, and Wimbledon and the French and US Opens are with us. In tennis, does the man with the fastest serve win? And can you make too few unforced errors for success? Sarah Budrus, Susan VanderPlas and Dianne Cook analyse what gets the star players to match point.},
  year = {2013},
  keywords = {npr, visualization, data science},
  author+an = {2=highlight},
  pic = {https://rss.onlinelibrary.wiley.com/cms/asset/b0ea4265-b5ea-4025-8345-6de8bf26f7c2/sign665-fig-0001-m.png}
}
@Article{towfic2010detection,
  title = {Detection of gene orthology from gene co-expression and protein interaction networks},
  author = {Towfic, Fadi  and Vanderplas, Susan and Oliver, Casey A  and Couture, Oliver  and Tuggle, Christopher K  and Greenlee, M Heather West  and Honavar, Vasant },
  journal = {BMC bioinformatics},
  year = {2010},
  date = {2010-04-29},
  number = {Suppl 3},
  pages = {S7},
  volume = {11},
  publisher = {BioMed Central Ltd},
  doi = {https://doi.org/10.1186/1471-2105-11-S3-S7},
  keywords = {pr, bioinformatics, undergraduate research},
  author+an = {2=highlight},
  pic = {https://i.imgur.com/8Wa9fu3.png}
}
@Article{hull2009near,
  title = {Near-infrared spectroscopy and cortical responses to speech production},
  author = {Hull, Rachel  and Bortfeld, Heather  and Koons, Susan },
  journal = {The open neuroimaging journal},
  doi = {https://doi.org/10.2174/1874440000903010026},
  year = {2009},
  date = {2009-04-03},
  pages = {26},
  volume = {3},
  publisher = {Bentham Science Publishers},
  abstract = {This research demonstrates near-infrared spectroscopy (NIRS) as a flexible methodology for measuring cortical activity during overt speech production while avoiding some limitations of traditional imaging technologies. Specifically, language production research has been limited in the number of participants and the types of paradigms that can be reasonably investigated using functional magnetic resonance imaging (fMRI) – where a sensitivity to motion has encouraged covert (i.e., nonvocalized) production paradigms – and positron emission tomography (PET), which allows a greater range of motion but introduces practical and ethical limitations to the populations that can be studied. Moreover, for these traditional technologies, the equipment is expensive and not portable, effectively limiting most studies to small, local samples in a relatively few labs. In contrast, NIRS is a relatively inexpensive, portable, noninvasive alternative that is robust to motion artifacts associated with overt speech production. The current study shows that NIRS data is consistent with behavioral and traditional imaging data on cortical activation associated with overt speech production. Specifically, the NIRS data show robust activation in the left temporal region and no significant change in activation in the analogous right hemisphere region in a sample of native, English-speaking adults in a picture-naming task. These findings illustrate the utility of NIRS as a valid method for tracking cortical activity and advance it as a powerful alternative when traditional imaging techniques are not a viable option for researchers investigating the neural substrates supporting speech production.},
  keywords = {pr, psychology, cognition, undergraduate research},
  author+an = {3=highlight},
  pic = {https://i.imgur.com/hXnipcb.png}
}
